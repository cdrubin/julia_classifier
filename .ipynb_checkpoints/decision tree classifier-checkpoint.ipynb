{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The building blocks of a Decision Tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to calculate [entropy](https://bricaud.github.io/personal-blog/entropy-in-decision-trees/)\n",
    "\n",
    "To help establish how much disorder there is the data we calculate entropy. \n",
    "\n",
    "First let us establish the naive probability of an attribute that divides the data into two labels $n,m$:\n",
    "\n",
    "\n",
    "$$ p(n) = 1 - p(m) $$\n",
    "\n",
    "since the sum of the probability of n and m equals $ 1 $. Let us say $ q = p(n) = \\frac{|n|}{|n|+|m|} $ and $ r = p(m) = \\frac{|m|}{|n|+|m|} $ we define their entropy as:\n",
    "\n",
    "$$ H(m,n) = - q \\log(q) - r \\log(r) $$\n",
    "\n",
    "Which generalizes for an attribute that divides data into $ K $ labels:\n",
    "\n",
    "$$ H = - \\sum_{i=1}^K p_i \\log(p_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to pick nodes\n",
    " - A chosen attribute $A$, with $K$ distinct values divides the training set $E$ into subsets $E_1,...E_K$.\n",
    " - The __Expected Entropy__ (__EH__) remaining after trying attribute $A$ (with branches $i=1,2,...,K$ is:\n",
    " \n",
    " $$ EH(A) = \\sum_{i=1}^{K} \\frac{p_i + n_i}{p + n} \\cdot H \\left( \\frac{p_i}{p_i + n_i},\\frac{n_i}{p_i+n_i} \\right) $$\n",
    " - Where $ p_i $ are the number of datums that do descend along branch $ i $, while $ n_i $ are the number that do not. \n",
    " \n",
    " - The __Information Gain__ (__I__) or reduction in entopy for this attribute is:\n",
    " \n",
    " $$ I(A) = H \\left( \\frac{p}{p+n},\\frac{n}{p+n} \\right) - EH(A) $$\n",
    " \n",
    " - Choose the attribute with the highest I.\n",
    " \n",
    " <mark>TODO: Understand what the p and q (without subscripts) represent above. Also, watch the Google video on creating a classifier now!</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×12 Array{Any,2}:\n",
       " \"Datum\"  \"Alt\"  \"Bar\"  \"Fri\"  \"Hun\"  …  \"Type\"     \"Est\"    \"WillWait\"\n",
       " \"X1\"     \"T\"    \"F\"    \"F\"    \"T\"       \"French\"   \"0-10\"   \"T\"       \n",
       " \"X2\"     \"T\"    \"F\"    \"F\"    \"T\"       \"Thai\"     \"30-60\"  \"F\"       \n",
       " \"X3\"     \"F\"    \"T\"    \"F\"    \"F\"       \"Burger\"   \"0-10\"   \"T\"       \n",
       " \"X4\"     \"T\"    \"F\"    \"T\"    \"T\"       \"Thai\"     \"10-30\"  \"T\"       \n",
       " \"X5\"     \"T\"    \"F\"    \"T\"    \"F\"    …  \"French\"   \">60\"    \"F\"       \n",
       " \"X6\"     \"F\"    \"T\"    \"F\"    \"T\"       \"Italian\"  \"0-10\"   \"T\"       \n",
       " \"X7\"     \"F\"    \"T\"    \"F\"    \"F\"       \"Burger\"   \"0-10\"   \"F\"       \n",
       " \"X8\"     \"F\"    \"F\"    \"F\"    \"T\"       \"Thai\"     \"0-10\"   \"T\"       \n",
       " \"X9\"     \"F\"    \"T\"    \"T\"    \"F\"       \"Burger\"   \">60\"    \"F\"       \n",
       " \"X10\"    \"T\"    \"T\"    \"T\"    \"T\"    …  \"Italian\"  \"10-30\"  \"F\"       \n",
       " \"X11\"    \"F\"    \"F\"    \"F\"    \"F\"       \"Thai\"     \"0-10\"   \"F\"       \n",
       " \"X12\"    \"T\"    \"T\"    \"T\"    \"T\"       \"Burger\"   \"30-60\"  \"T\"       "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Pkg.add(\"CSV\")\n",
    "\n",
    "training_data = readcsv( \"training_data.csv\" )\n",
    "show( training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above data I seek to find the attribute that best splits the data into \"WillWait\" or not. \n",
    "\n",
    "For a training set like this with positive and negative examples we can use the following:\n",
    "\n",
    "$$ H \\left( \\frac{p}{p+n}, \\frac{n}{p+n} \\right) = - \\frac{p}{p+n} log_2 \\frac{p}{p+n} - \\frac{p}{p+n} log_2 \\frac{p}{p+n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this training set, lets consider how _good_ the attributes \"Patron\" and \"Type\" are at splitting the \"WillWait\" values:\n",
    "\n",
    "For the training set $ p = n = 6 $ (there are six negative \"WillWait\" values and six positive) = 1 bit\n",
    "\n",
    "$$ IG(Patron) = 1 - \\left[ EH(Patron_{None}) + EH(Patron_{Some}) + EH(Patron_{Full}) \\right] $$\n",
    "\n",
    "$$ IG(Patron) = 1 - \\left[ \\frac{2}{12}H \\left( \\frac{0}{2}, \\frac{2}{2} \\right) + \\frac{4}{12}H \\left( \\frac{4}{4}, \\frac{0}{4} \\right) + \\frac{6}{12}H\\left( \\frac{2}{6}, \\frac{4}{6} \\right) \\right] = 0.0541 bits $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
